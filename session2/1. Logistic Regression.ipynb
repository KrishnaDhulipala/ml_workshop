{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regression: Logistic Regression\n",
    "In this introduction, we will develop logistic regression from basic principles.  Other tutorials will forgo the theory and focus on existing python libraries that are commonly used for building regression models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All good python projects begin with specifying which modules to load\n",
    "\n",
    "import pandas as pd  # Pandas is a package which creates data frames\n",
    "import numpy as np # Numpy is the package which creates/manages/operates on numerical data\n",
    "import matplotlib.pyplot as plt # Matplotlib is the plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "As we covered in the last session, regression is a method for fitting the parameters of a presumed model to our data. In logistic regression, the dependent output data is the probability that the independent inputs belong to a given classification.\n",
    "\n",
    "For example, say the input variables are the height and weight of a person. The output could be the probability that the person is a male. This can be applied to binary classes, such as yes/no or success/failure. It can also be used for multiple classes, such as identification of an animal to a specific species.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Every project begins with the data.  We will be using data that _Tjen-Sien Lim_ (limt@stat.wisc.edu) supplied. The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\n",
    "\n",
    "//=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "Dataset:  haberman.data\n",
    "Lim, Tjen-Sien (1999). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Variables/Columns\n",
    "\n",
    "1. Age of patient at time of operation (numerical) <br>\n",
    "2. Patient's year of operation (year - 1900, numerical)<br> \n",
    "3. Number of positive axillary nodes detected (numerical) <br>\n",
    "4. Survival status (class attribute) <br>\n",
    "-- 1 = the patient survived 5 years or longer <br>\n",
    "-- 2 = the patient died within 5 year <br>\n",
    "\n",
    "//=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the data directly from github\n",
    "haber = 'http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data'\n",
    "\n",
    "# Data does not have a header row so we have to label the data\n",
    "names = ['age', 'year', 'nodes', 'survival']\n",
    "data = pd.read_csv(haber, header=None, names=names)\n",
    "\n",
    "# We will change the survival labels\n",
    "# 1-> 1 : No change\n",
    "# 2-> 0 : Death within 5 years is 0\n",
    "data['survival']=-1*(data['survival']-2)\n",
    "\n",
    "# head() gives a snapshot of the data.  Jupyterhub is great a rendering tables.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() provides more summary information from the data (also in a nice rendered table)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter can show us the data\n",
    "plt.scatter(data['age'], data['survival'],color='r')\n",
    "plt.title('Age and Survival')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survival [1=No; 2=Yes]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter can show us the data\n",
    "plt.scatter(data['nodes'], data['survival'],color='r')\n",
    "plt.title('Number of Nodes and Survival')\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Survival [1=No; 2=Yes]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter can show us the data\n",
    "plt.scatter(data['year'], data['survival'],color='r')\n",
    "plt.title('Year of Surgery and Survival')\n",
    "plt.xlabel('Year of Surgery')\n",
    "plt.ylabel('Survival [1=No; 2=Yes]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model buiding\n",
    "\n",
    "A logistic regression model uses the log-odds regression fit. If $p$ is the probability of survival, then the log-odds of survival is:\n",
    "\n",
    "$$\n",
    "L = \\log \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "And to fit this to 3 input variables:\n",
    "\n",
    "$$\n",
    "L = \\log \\frac{p}{1-p} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3\n",
    "$$\n",
    "\n",
    "So, now we have the inputs, $x$, and we need to find the scalars, $\\beta$, that fit our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Variable\n",
    "\n",
    "Let's begin with only solving the relationship of age to survival. First, we will define the logit function:\n",
    "\n",
    "$$\n",
    "\\sigma(t) = \\frac{e^t}{e^t+1} = \\frac{1}{1+e^{-t}}\n",
    "$$\n",
    "\n",
    "Where $t$ is our linear equation:\n",
    "\n",
    "$$\n",
    "t = \\beta_0 + \\beta_1 x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict()\n",
    "model['b0'] = ________\n",
    "model['b1'] = ________\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData = pd.DataFrame({'x': data['age'],'y': data['survival']})\n",
    "modelData['y_'] = 1/(1+np.exp(-1*(model['b1'] * modelData['x']  +  model['b0'])))\n",
    "\n",
    "modelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how we did\n",
    "plt.scatter(modelData['x'],modelData['y'],color='r')\n",
    "plt.scatter(modelData['x'],modelData['y_'],color='g')\n",
    "plt.plot(modelData['x'],modelData['y_'],color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaulation\n",
    "\n",
    "We need a metric to determine how good the model is.  Thoughts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData['delta'] = modelData['y'] - modelData['y_']\n",
    "modelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData['squared'] = modelData['delta']*modelData['delta']\n",
    "modelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = sum(modelData['squared'])/modelData['squared'].count()\n",
    "sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "# Ok, Now go back and try different values for b0 and b1.\n",
    "# Can you do better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
