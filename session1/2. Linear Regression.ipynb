{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regression: Linear Regression\n",
    "\n",
    "In this introduction, we will develop linear regression from basic principles.  Other tutorials will forgo the theory and focus on existing python libraries that are commonly used for building regression models.\n",
    "\n",
    "In our line fitting exercise, we manual tweeked the model parameters.  While that was certainly fun for about 1 min, it probably became tedious.  We want to automate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All good python projects begin with specifying which modules to load\n",
    "\n",
    "import pandas as pd  # Pandas is a package which creates data frames\n",
    "import numpy as np # Numpy is the package which creates/manages/operates on numerical data\n",
    "import matplotlib.pyplot as plt # Matplotlib is the plotting library\n",
    "\n",
    "# This allow for multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Every project begins with the data.  We will be using example data that _Fedor Karmanov_ has created based on some published literature.  Visit Fedor's github repo to learn more (https://github.com/fed-ka/springboard)\n",
    "\n",
    "//=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "Dataset:  lsd.dat\n",
    "Source: Wagner, Agahajanian, and Bing (1968). Correlation of Performance\n",
    "Test Scores with Tissue Concentration of Lysergic Acid Diethylamide in\n",
    "Human Subjects. Clinical Pharmacology and Therapeutics, Vol.9 pp635-638.\n",
    "\n",
    "Description: Group of volunteers was given LSD, their mean scores on\n",
    "math exam and tissue concentrations of LSD were obtained at n=7 time points.\n",
    "\n",
    "Variables/Columns\n",
    "\n",
    "Tissue Concentration    1-4 <br>\n",
    "Math Score             8-12\n",
    "\n",
    "//=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the data directly from github\n",
    "lsd = 'https://raw.githubusercontent.com/fed-ka/springboard/master/5.%20Linear%20Regressions%20in%20Python/lsd.csv'\n",
    "data = pd.read_csv(lsd)\n",
    "\n",
    "# Skip the data exploration and just get back to a basic model\n",
    "\n",
    "# Model\n",
    "model = dict()\n",
    "model['m'] = 0\n",
    "model['b'] = 0\n",
    "\n",
    "# Since there is no model yet, y_ can be filled with 0\n",
    "modelData = pd.DataFrame({'x': data['Tissue Concentration'],\n",
    "                          'y': data['Test Score'], \n",
    "                          'y_': np.zeros(data['Test Score'].count())})\n",
    "\n",
    "\n",
    "print('Model')\n",
    "model\n",
    "print('Model Data')\n",
    "modelData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalize the problem\n",
    "\n",
    "We know:\n",
    "\n",
    "$y_i = m*x_i + b$ _for all i samples_\n",
    "\n",
    "The model that we are building is:\n",
    "\n",
    "$\\bar{y} = m*x + b$\n",
    "\n",
    "The error that we have defined is:\n",
    "\n",
    "$mse = \\frac{1}{N} \\sum{( y_i - \\bar{y}(x_i) )^2}$\n",
    "\n",
    "The expanded form of this is:\n",
    "\n",
    "$mse = \\frac{1}{N} \\sum{(y_i - (m*x_i + b))^2}$\n",
    "\n",
    "We want to minimize the error.  This is accomplished with gradient descent.  To use the gradient descent, we need the gradient with respect to each of the parameters that we are tweeking:\n",
    "\n",
    "$\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial m} mse &= \\\\\n",
    "&= \\frac{\\partial}{\\partial m} \\frac{1}{N} \\sum{(y_i - (m*x_i + b))^2} \\\\\n",
    "&= \\frac{1}{N} \\sum{ \\frac{\\partial}{\\partial m}  (y_i - (m*x_i + b))^2}\\\\\n",
    "&= \\frac{2}{N} \\sum{ -x_i (y_i - (m*x_i + b))} \\\\\n",
    "&= \\frac{2}{N} \\sum{ -x_i (y_i - \\bar{y_i})}\n",
    "\\end{aligned}$\n",
    "\n",
    "$\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial b} mse &= \\\\\n",
    "&= \\frac{\\partial}{\\partial b} \\frac{1}{N} \\sum{(y_i - (m*x_i + b))^2} \\\\\n",
    "&= \\frac{1}{N} \\sum{ \\frac{\\partial}{\\partial b}  (y_i - (m*x_i + b))^2}\\\\\n",
    "&= \\frac{2}{N} \\sum{ -(y_i - (m*x_i + b))} \\\\\n",
    "&= \\frac{2}{N} \\sum{ -(y_i - \\bar{y_i})}\n",
    "\\end{aligned}$\n",
    "\n",
    "Now we can convert this into code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeModelAndError (model, modelData):\n",
    "    \n",
    "    # Compute model\n",
    "    modelData['y_'] = model['m'] * modelData['x']  +  model['b']\n",
    "\n",
    "    # Compute SSE\n",
    "    modelData['delta'] = modelData['y'] - modelData['y_']\n",
    "    modelData['squared'] = modelData['delta']*modelData['delta']\n",
    "\n",
    "    model['mse'] = sum(modelData['squared'])/modelData['squared'].count()\n",
    "    \n",
    "    return model, modelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradMSE(model, modelData):\n",
    "    # We are going to be summing the gradient for each point that we are testing with\n",
    "    b_gradient = 0 \n",
    "    m_gradient = 0     \n",
    "    N = float(modelData.x.count())\n",
    "\n",
    "    for i in range(0, modelData.x.count()): \n",
    "        m_gradient += -(modelData.x[i] * (modelData.y[i] - modelData.y_[i]))\n",
    "        b_gradient += -(modelData.y[i] - modelData.y_[i]) \n",
    "\n",
    "    model['gradm'] = (2/N*m_gradient)\n",
    "    model['gradb'] = (2/N*b_gradient)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gradient descent, you take the existing model parameters (m and b) and adjust them based on the gradient (which will point downhill).  The rate at which you adjust the parameters is called the \"learning rate.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradDescent(model,modelData,learningRate):\n",
    "    # Given the current model, determine the gradients\n",
    "    model = gradMSE(model,modelData)\n",
    "    \n",
    "    # Given the gradients, we can estimate new parameters\n",
    "    model['m'] = model['m'] - (learningRate * model['gradm']) \n",
    "    model['b'] = model['b'] - (learningRate * model['gradb']) \n",
    "    \n",
    "    return model    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the learning\n",
    "\n",
    "Stepping through the learning one step at a time:\n",
    "\n",
    "1) Start with a guess\n",
    "2) Compute the model\n",
    "3) Apply Gradient Descent\n",
    "4) Compute the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Pulled from manual task\n",
    "learningRate = _____\n",
    "model['m'] = _______\n",
    "model['b'] = _______\n",
    "\n",
    "\n",
    "# Step 2 - Compute model\n",
    "[model,modelData] = computeModelAndError (model, modelData)\n",
    "    \n",
    "print('Current Model')\n",
    "model\n",
    "modelData\n",
    "\n",
    "plt.scatter(modelData['x'],modelData['y'],color='r')\n",
    "plt.scatter(modelData['x'],modelData['y_'],color='g')\n",
    "plt.plot(modelData['x'],modelData['y_'],color='b')\n",
    "plt.show()\n",
    "\n",
    "# Step 3 - Apply grad \n",
    "\n",
    "model = gradDescent(model,modelData,learningRate)\n",
    "        \n",
    "# Step 4 - Compute new model\n",
    "[model,modelData] = computeModelAndError (model, modelData)\n",
    "print('New Model')\n",
    "model\n",
    "modelData\n",
    "\n",
    "plt.scatter(modelData['x'],modelData['y'],color='r')\n",
    "plt.scatter(modelData['x'],modelData['y_'],color='g')\n",
    "plt.plot(modelData['x'],modelData['y_'],color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "# Adjust the starting values for m and b\n",
    "# Adjust the learning rate.  Observe the impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "# Step 1 - Pulled from manual task\n",
    "learningRate = ____\n",
    "model['m'] = ______\n",
    "model['b'] = ______\n",
    "\n",
    "# Step 2 - Compute model\n",
    "[model,modelData] = computeModelAndError (model, modelData)\n",
    "    \n",
    "print('Initial Model')\n",
    "model\n",
    "modelData\n",
    "\n",
    "# The use of \"_ =\" suppresses the intermediate output.\n",
    "_ = plt.scatter(modelData['x'],modelData['y'],color='r')\n",
    "_ = plt.scatter(modelData['x'],modelData['y_'],color='g')\n",
    "_ = plt.plot(modelData['x'],modelData['y_'],color='b')\n",
    "plt.show()\n",
    "\n",
    "# Run it with a loop\n",
    "\n",
    "runs = pd.DataFrame({'m': {}, 'b': {}, 'mse': {}})\n",
    "\n",
    "runs = runs.append({'m': model['m'], 'b': model['b'], 'mse': model['mse']}, ignore_index=True)\n",
    "for i in range(0,10):\n",
    "    # Step 3 - Apply grad \n",
    "    model = gradDescent(model,modelData,learningRate)\n",
    "\n",
    "    # Step 4 - Compute new model\n",
    "    [model,modelData] = computeModelAndError (model, modelData)\n",
    "    \n",
    "    runs = runs.append({'m': model['m'], 'b': model['b'], 'mse': model['mse']}, ignore_index=True)\n",
    "\n",
    "print('Final Model')\n",
    "model\n",
    "modelData\n",
    "\n",
    "_ = plt.scatter(modelData['x'],modelData['y'],color='r')\n",
    "_ = plt.scatter(modelData['x'],modelData['y_'],color='g')\n",
    "_ = plt.plot(modelData['x'],modelData['y_'],color='b')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Runtime Paramers')\n",
    "runs\n",
    "_ = plt.subplot(131)\n",
    "_ = plt.plot(runs.index,runs.m,color='b')\n",
    "_ = plt.title('m')\n",
    "_ = plt.subplot(132)\n",
    "_ = plt.plot(runs.index,runs.b,color='b')\n",
    "_ = plt.title('b')\n",
    "_ = plt.subplot(133)\n",
    "_ = plt.plot(runs.index,runs.mse,color='b')\n",
    "_ = plt.title('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "# Run the model with several different initialized parameters\n",
    "# What do the training plots tell you?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
